{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>หลักการประมาณด้วยความเป็นไปได้สูงสุดและโมเมนต์\n",
    "## <center>Maximum Likelihood Estimation and Method of Moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## บทนำ\n",
    "<p>หัวข้อนี้จะนำเสนอหลักการพื้นฐานของการประมาณค่า (estimation) โดยพิจารณาวิธีการประมาณค่าอีก 2 วิธี\n",
    "    <p>$\\rightarrow$ วิธีการประมาณค่าด้วยความเป็นไปได้สูงสุด (Maximum Likelihood Estimation หรือเรียกสั้นๆ ว่า MLE)\n",
    "<p>$\\rightarrow$ วิธีการประมาณค่าด้วยโมเมนต์(Method of Moments หรือเรียกสั้นๆ ว่า MM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## นิยาม: ฟังก์ชันความเป็นไปได้ (likelihood function)\n",
    "<p>หลักการสำคัญของการประมาณค่าด้วยความเป็นไปได้สูงสุด (Maximum Likelihood Estimation หรือเรียกสั้นๆ ว่า MLE) <p>$\\rightarrow$ ข้อมูลที่ได้จากการสังเกตเกิดจากการสุ่มเลือกมา\n",
    "จากประชากรที่มีการแจกแจงที่ <b>ขึ้นอยู่กับค่าพารามิเตอร์เฉพาะค่าหนึ่ง</b> ซึ่งควรจะเป็นค่าที่ทำให้ความเป็นไปได้ (likelihood) ที่จะสุ่มเลือกได้ตัวอย่างดังกล่าวมีค่าสูงสุด\n",
    "    <p><b>Definition</b>\n",
    "ฟังก์ชันความเป็นไปได้ (likelihood function) คือ <b>ฟังก์ชันความหนาแน่นของความน่าจะเป็นร่วม</b> (Joint Probabillity Density Function) หรือ <b>ฟังก์ชันความน่าจะเป็นร่วม</b> (Joint Probabillity Function) $f (x| \\theta) $ โดยที่\n",
    "$x = (x_1, \\cdots, x_n)$ คือ ค่าที่เกิดขึ้นจริงที่ได้จากข้อมูล\n",
    "        <p>รูปแบบของฟังก์ชันความเป็นไปได้(likelihood function) ขึ้นอยู่กับ<b>ข้อมูลที่ได้จากการสังเกต</b>\n",
    "            <p>$\\rightarrow$ หากตัวแปรที่เกี่ยวข้องเป็นแบบไม่ต่อเนื่อง (discrete) ฟังก์ชันความเป็นไปได้ (likelihood\n",
    "function) ก็จะอยู่ในรูปแบบฟังก์ชันความน่าจะเป็นร่วม (Joint Probabillity Function) ถึงแม้ว่าตัวแปรสุ่มพื้น\n",
    "ฐานที่ระบุในแบบจำลองจะเป็นแบบต่อเนื่องก็ตาม\n",
    "                <p>อีกด้านหนึ่ง ฟังก์ชันความเป็นไปได้ (likelihood function) ก็เป็น<b>ฟังก์ชันของพารามิเตอร์ที่ต้องการทราบค่า $\\theta$</b> โดยมองว่าค่าของ $x = (x_1,\\cdots,x_n)$ เป็นเพียงค่าคงที่ซึ่ง <b>ทราบค่าแล้วจากข้อมูลที่มีอยู่</b>\n",
    "                    <p>ตัวประมาณค่าด้วยความเป็นไปได้สูงสุด (MLE) หมายถึง <b>การแก้ปัญหาการหาค่าสูงสุดซึ่ง\n",
    "มีฟังก์ชันความเป็นไปได้ (likelihood function) เป็นฟังก์ชันจุดประสงค์ (objective\n",
    "function)</b> และพารามิเตอร์ที่ต้องการทราบค่า $\\theta$ เป็นตัวแปรที่ต้องเลือก"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## นิยาม: ตัวประมาณด้วยความเป็นไปได้สูงสุด (Maximum Likelihood Estimation)\n",
    "<p><b>Definition</b> พิจารณาข้อมูลที่สังเกตได้ (observed data) $x$ ชุดหนึ่ง และ $\\boldsymbol{\\hat{\\theta}}_{MLE}(x)$ เป็นคำตอบของปัญหา\n",
    "การหาค่าสูงสุด (maximization problem) ต่อไปนี้ <p><center>$f(x|\\boldsymbol{\\hat{\\theta}}_{MLE}(x))= \\begin{equation} \n",
    "\\max\\limits_{\\theta} f(x | \\theta)\\end{equation}\\ หรือ\\   \\boldsymbol{\\hat{\\theta}}_{MLE}(x) =arg\\max\\limits_{\\theta} f(x | \\theta) $\n",
    "    <p>แล้วฟังก์ชัน $\\boldsymbol{\\hat{\\theta}}_{MLE}(X)$ คือ <b>ตัวประมาณค่า</b> ด้วยความเป็นไปได้สูงสุด (Maximum Likelihood\n",
    "Estimator หรือเรียกสั้นๆ ว่า MLE) <p>และ $\\boldsymbol{\\hat{\\theta}}_{MLE} (x) $คือ ค่าประมาณด้วยความเป็นไปได้สูงสุดของ\n",
    "$\\theta$ เมื่อข้อมูลที่ใช้ในการประมาณค่าคือ $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## การประมาณค่าด้วยความเป็นไปได้สูงสุด (Maximum Likelihood Estimation)\n",
    "<p>$\\rightarrow$ ฟังก์ชันความเป็นไปได้ (likelihood function) มักอยู่ในรูปของ <b>ผลคูณของฟังก์ชันความหนาแน่นของความน่าจะเป็น (Probabillity Density Function) <p>หรือฟังก์ชันความน่าจะเป็น (Probabillity Function)</b>\n",
    "    <p>$\\rightarrow$ เพื่อความสะดวกจึงมักจะ <b>แปลงฟังก์ชันจุดประสงค์(objective function) ให้อยู่ในรูปของล็อกการิธึม</b> แทน ซึ่งจะอยู่ในรูปของผลบวกซึ่งจัดการได้ง่ายกว่ามากและที่สำคัญยังได้คำตอบเท่าเดิม\n",
    "       <p>$\\rightarrow$  การแปลงค่าฟังก์ชันจุดประสงค์โดยใช้<b>ฟังก์ชันที่เพิ่มขึ้นทางเดียว (monotonically increasing)</b> จะ<b>ไม่</b>ทำให้คำตอบของปัญหาการหาค่าสูงสุดเปลี่ยนไป"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ตัวอย่าง: การประมาณค่าด้วยการแจกแจงแบบเบอร์นูลลี(Bernoulli distribution)\n",
    "<b>Example</b> พิจารณาตัวอย่าง $X_1, \\cdots, Xn$ โดยที่ $X_i$ มีการแจกแจงแบบเบอร์นูลลี(Bernoulli distribution) สำหรับพารามิเตอร์ $\\theta$ ซึ่งเป็นสิ่งที่\n",
    "ต้องการประมาณค่า และกำหนดให้ $x = (x_1, \\cdots, x_n)$ คือค่าที่เกิดขึ้นจริงที่ได้จากข้อมูล\n",
    "<p>$\\rightarrow$ ฟังก์ชันความเป็นไปได้(likelihood function) ในกรณีนี้เท่ากับ\n",
    "    <p><center>$\\mathscr{L}=\\prod\\limits_{n=1}^n \\theta^{x_i}(1-\\theta)^{1-x_i} $\n",
    "        <p>$\\rightarrow$ ฟังก์ชันล็อกการิธึมของความเป็นไปได้(log-likelihood function) เท่ากับ\n",
    "            <p><center>$\\log\\ \\mathscr{L}= \\sum\\limits_{i=1}^{n}[x_i \\log \\theta+(1-x_i)\\log(1- \\theta)]=\\left(\\sum\\limits_{i=1}^{n}x_i\\right) \\log \\theta+\\left(n-\\sum\\limits_{i=1}^{n}x_i\\right) \\log(1-\\theta) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## สรุป: การประมาณค่าด้วยการแจกแจงแบบเบอร์นูลลี(Bernoulli distribution)\n",
    "<p><b>Example</b>\n",
    "<p>$\\rightarrow$ ปัญหาการหาค่าสูงสุดในกรณีคือ <p><center>$\\max\\limits_{\\theta}\\left(\\sum\\limits_{i=1}^{n}x_i\\right) \\log \\theta+\\left(n-\\sum\\limits_{i=1}^{n}x_i\\right) \\log(1-\\theta)$\n",
    "  <p>$\\rightarrow$  เราสามารถหาคำตอบได้โดยการกำหนดให้ค่าอนุพันธ์อันดับที่หนึ่งของฟังก์ชันจุดประสงค์(objective function) หรือฟังก์ชันล็อกการิธึมของความเป็นไปได้(log-likelihood function) เท่ากับศูนย์หรือที่เรียกว่า เงื่อนไขอันดับที่หนึ่ง (first-order\n",
    "conditions) <p><center>$\\frac{\\partial \\log \\mathscr{L}}{\\partial \\theta}\\Big|_{\\boldsymbol{\\hat{\\theta}}_{MLE}(x))} = 0 \\Rightarrow \\left(\\sum\\limits_{i=1}^{n}x_i\\right) \\frac{1}{\\boldsymbol{\\hat{\\theta}}_{MLE}(x)}-\\left(n-\\sum\\limits_{i=1}^{n}x_i\\right)\\frac{1}{1-\\boldsymbol{\\hat{\\theta}}_{MLE}(x)}=0$ <p><center> $\\Rightarrow \\boldsymbol{\\hat{\\theta}}_{MLE}(x)=\\left(\\frac{\\sum\\limits_{i=1}^{n}x_i}{n}\\right) = \\bar{X}_n$\n",
    "    <p>$\\rightarrow$ ตัวประมาณค่าด้วยความเป็นไปได้สูงสุด (MLE): $\\boldsymbol{\\hat{\\theta}}_{MLE}(x)=\\left(\\frac{\\sum\\limits_{i=1}^{n}x_i}{n}\\right) = \\bar{X}_n$\n",
    "        <p>$\\rightarrow$ ตัวประมาณค่าด้วยความเป็นไปได้สูงสุด (MLE) : $\\boldsymbol{\\hat{\\theta}}_{MLE}(x)$ เป็น <b>ฟังก์ชันของตัวอย่าง $X$ </b>แต่หลังจากนี้ต่อไป จะขอไม่เขียนส่วนนี้ทั้งนี้เพื่อความกระชับ โดยจะเขียนสั้นๆ เป็น $\\boldsymbol{\\hat{\\theta}}_{MLE}$ แต่ขอให้เข้าใจว่ามันคือ $\\boldsymbol{\\hat{\\theta}}_{MLE}(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ตัวอย่าง: การประมาณค่าด้วยการแจกแจงแบบปกติ (normal distribution)\n",
    "\n",
    "**<u>Example</u>**\n",
    "สมมติให้ $x_1, . . . , x_n$ เป็นกลุ่มตัวอย่างที่เลือกมาการแจกแจงแบบปกติ (normal distribution) ที่มีค่าคาดหมาย µ และค่าความแปรปรวน $σ^2$ โดยทั้งสองเป็นพารามิเตอร์ที่ต้องการทราบค่า และกำหนดให้ $ x = (x_1, . . . , x_n) $ คือค่าที่เกิดขึ้นจริงที่ได้จากข้อมูล\n",
    "\n",
    "* ฟังก์ชันความเป็นไปได้ (likelihood function) ในกรณีนี้เท่ากับ\n",
    "<div align=\"right\"></div>\n",
    "$$ \\mathscr{L} = \\prod_{i = 1}^{n} ϕ \\left( \\frac{x_i - µ}{σ} \\bigg| µ,σ^2 \\right)$$\n",
    "\n",
    "* ฟังก์ชันล็อกการิธึมของความเป็นไปได้ (log-likelihood function) เท่ากับ\n",
    "<div align=\"right\"></div>\n",
    "$$ log \\mathscr{L} = - \\frac{n}{2} log(2π) - \\frac{n}{2}log σ^2 - \\frac{1}{2σ^2} \\sum_{i = 1}^{n} (x_i -  µ)^2 $$\n",
    "\n",
    "* ปัญหาการหาค่าสูงสุดในกรณีคือ\n",
    "$$ \\max_{µ, σ^2} - \\frac{n}{2} log(2π) - \\frac{n}{2}log σ^2 - \\frac{1}{2σ^2} \\sum_{i = 1}^{n} (x_i -  µ)^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## สรุป: การประมาณค่าด้วยการแจกแจงแบบปกติ (normal distribution)\n",
    "\n",
    "**<u>Example</u>**\n",
    "\n",
    "* เงื่อนไขอันดับหนึ่ง (first-order conditions) ของปัญหานี้เท่ากับ\n",
    "<div align=\"right\"></div>\n",
    "$ \\frac{∂ log\\mathscr{L}}{∂µ} \\bigg|_{{\\hatµ _{MLE}},{\\hatσ_{MLE}^2}} = 0 \\rightarrow \\frac{1}{\\hatσ_{MLE}^2} \\sum_{i = 1}^{n} (x_i - \\hatµ_{MLE}) = 0$\n",
    "\n",
    "<div align=\"right\"></div>\n",
    "$ \\frac{∂ log\\mathscr{L}}{∂σ^2} \\bigg|_{{\\hatµ _{MLE}},{\\hatσ_{MLE}^2}} = 0 \\rightarrow -\\frac{n}{2\\hatσ_{MLE}^2} + \\frac{1}{2(\\hatσ_{MLE}^2)^2} \\sum_{i = 1}^{n} (x_i - \\hatµ_{MLE})^2 = 0$\n",
    "\n",
    "* ระบบสมการข้างต้นมี 2 ตัวแปร และสามารถหาคำตอบได้เป็น\n",
    "<div align=\"right\"></div>\n",
    "$$ \\hatµ_{MLE} = \\frac{ \\sum_{i=1}^n x_i}{n} = \\overline x_n ,$$\n",
    "$$ \\hatσ_{MLE}^2 = \\frac{1}{n} (x_i - \\overline{x}_n)^2$$\n",
    "\n",
    "* เรามักเรียกตัวประมาณค่าสำหรับค่าคาดหมาย $\\overline{x}_n$ ว่า **ค่าคาดหมายจากตัวอย่าง (sample mean)**\n",
    "\n",
    "\n",
    "* ตัวประมาณค่าสำหรับค่าความแปรปรวน $ \\frac {1}{n} (x_i - x_n)^2$ ว่า **ค่าความแปรปรวนจากตัวอย่าง  (sample variance)** ซึ่งแตกต่างจาก $ S_n^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - x_n)^2$ ตรงที่ส่วนตัวหารที่ $ \\hatσ_{MLE}{2} $ นั้นหารด้วย $n$ แต่ $ S_n^2$ หารด้วย $n-1$\n",
    "\n",
    "\n",
    "* ตัวประมาณค่าทั้งสองของความแปรปรวนนี้มี **คุณสมบัติลู่เข้าเชิงความน่าจะเป็นที่เหมือนกัน** เพราะ $n$ และ $n-1$ นั้นมีพฤติกรรมที่ลิมิตเหมือนกัน แต่มี**คุณสมบัติความไม่เบี่ยงเบน (unbiasness) ต่างกัน**อภิปรายในรายละเอียดในหัวข้อถัดไป"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ตัวอย่าง: การประมาณค่าด้วยการแจกแจงแบบเอกรูป (uniform distribution)\n",
    "\n",
    "**<u>Example</u>**\n",
    "สมมติให้ $x_1, . . . , x_n$ เป็นกลุ่มตัวอย่างที่เลือกมาการแจกแจงแบบเอกรูป (uniform\n",
    "distribution) ในช่วง $[0,c]$ โดย c คือพารามิเตอร์ที่ต้องการทราบค่า และกำหนดให้ $ x = (x_1, . . . , x_n) $ คือค่าที่เกิดขึ้นจริงที่ได้จากข้อมูล\n",
    "\n",
    "* ฟังก์ชันความเป็นไปได้ (likelihood function) ในกรณีนี้เท่ากับ\n",
    "<div align=\"right\"></div>\n",
    "$$ \\mathscr{L} = \\prod_{i = 1}^{n} \\frac{1}{c} = \\frac{1}{c^n}, $$\n",
    "สำหรับ  $0 \\le x_i \\le c $  สำหรับทุก $i = 1, . . .,n $\n",
    "\n",
    "\n",
    "* ส่วนกรณีอื่นๆ $ \\mathscr{L} = 0 $ ปัญหาการหาค่าสูงสุดในกรณีคือ\n",
    "\n",
    "$$ \\max_c \\frac{1}{c^n},$$\n",
    "โดยที่ $0 \\le x_i \\le c$  สำหรับทุก $i = 1, . . .,n $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## สรุป: การประมาณค่าด้วยการแจกแจงแบบเอกรูป (uniform distribution)\n",
    "\n",
    "* ปัญหานี้เป็นปัญหาการหาค่าสูงสุด **แบบมีข้อจำกัด** (constrained optimization problem)\n",
    "    * **หากไม่มีข้อจำกัด** คำตอบของ c ที่ทำให้ค่าฟังก์ชันความเป็นไปได้  (likelihood function) มีค่าสูงสุดคือ $c = 0$\n",
    "    * แต่จากข้อจำกัดนี้้ $ 0 ≤ x_i ≤ c $ ทำให้ค่า c จะต้องไม่น้อยกว่าค่า $x_i$ แต่ละค่า ซึ่งจะทำให้ $c = 0$ เป็นไปไม่ได้ (ยกเว้น $x_i = 0$ ทุกค่า ซึ่งเป็นกรณีที่ไม่น่าสนใจ)\n",
    "    * คำตอบของปัญหานี้จึงถูกกำหนดโดยข้อจำกัดเป็นหลัก นั่นคือ $ \\hat{c}_{MLE} \\ge x_i$ สำหรับทุก $ i = 1, . . .,n $\n",
    "    * แต่ในขณะเดียวกันฟังก์ชันวัตถุประสงค์ก็ต้องการให้ค่า $ \\hat{c}_{MLE}$ มีค่าต่ำที่สุดเท่าที่จะเป็นไปได้ ดังนั้น **คำตอบ** ที่ได้คือ $ \\hat{c}_{MLE} = max(x_1, . . . , x_n)$\n",
    "\n",
    "* บทเรียนทางคณิตศาสตร์อันหนึ่งในตัวอย่างนี้คือ บางครั้งเราอาจจะ **ไม่สามารถแก้ปัญหา**การหาค่าสูงสุดแบบทีข้อจำกัด (constrained optimization problem) ได้โดยใช้ **เงื่อนไขอันดับที่หนึ่ง (first-order conditions)** โดยตรงเหมือนกับตัวอย่างที่ผ่านมา\n",
    "* ทั้งนี้เพราะบางครั้ง **คำตอบที่ได้อาจจะอยู่บนขอบ (boundary) ของขอบเขตที่เป็นไปได้** ในขณะที่เงื่อนไขอันดับที่หนึ่ง (first-order conditions) ใช้ได้กับกรณีที่คำตอบอยู่ภายในขอบเขตที่เป็นไปได้ (interior solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ทฤษฎี: คุณสมบัติไม่แปรเปลี่ยน (invariance property) ของตัวประมาณ ค่าด้วยความเป็นไปได้สูงสุด (MLE)\n",
    "\n",
    "- ตัวประมาณค่าด้วยความเป็นไปได้สูงสุด (MLE) มีคุณสมบัติอย่างหนึ่งที่สำคัญที่ช่วยให้ สามารถประยุกต์ใช้ได้อย่างกว้างขวาง โดยเรามักเรียกคุณสมบัตินี้ว่า คุณสมบัติไม่แปร เปลี่ยน (invariance property) ซึ่งมีความหมายดังแสดงในทฤษฎีบทต่อไปนี้\n",
    "\n",
    "**Theorem**\n",
    "\n",
    "ถ้า $\\hat{\\theta}_{MLE}$ คือตัวประมาณค่าด้วยความเป็นไปได้สูงสุด (MLE) ของ $\\theta$ และ g เป็นฟังก์ชันที่กำหนด โดย  $\\gamma = g(\\theta)$ แล้ว $g(\\hat{\\theta}_{MLE})$ เป็นตัวประมาณค่าด้วยความเป็นไปได้สูงสุด (MLE) ของ $\\gamma$\n",
    "\n",
    "### การพิสูจน์: คุณสมบัติไม่แปรเปลี่ยน (invariance property) ของตัว ประมาณค่าด้วยความเป็นไปได้สูงสุด (MLE)\n",
    "**Proof**\n",
    "\n",
    "- เพื่อความสะดวก ขอนำเสนอ การพิสูจน์ในกรณีที่ g เป็นฟังก์ชันหนึ่งต่อหนึ่ง (one-on-one) เท่านั้น โดยเริ่มจาก การที่ $\\hat{\\theta}_{MLE}$ เป็นตัวประมาณค่าด้วยความเป็นไป ได้สูงสุด (MLE) ของ $\\theta$ หมายความว่า\n",
    "$$ \\hat{\\theta}_{MLE} = argmax_\\theta \\prod_{i=1}^{n}f_i(x_i|\\theta) ---------(10) $$\n",
    "\n",
    "- การที่ g เป็นฟังก์ชันหนึ่งต่อหนึ่ง (one-on-one) หมายความว่า เราสามารถใช้ฟังก์ชันส่วนกลับได้เป็น $\\theta = g^{−1} (\\gamma)$ ดังนั้น เราสามารถเขียนฟังก์ชันความเป็นไป ได้ (likelihood function) ในรูปฟังก์ชันของ $L$ ได้เป็น\n",
    "\n",
    "$$ L(\\gamma|x) = argmax_\\gamma \\prod_{i=1}^{n}f_i(x_i|g^{-1}(\\gamma)) ---------(11) $$\n",
    "\n",
    "- ดังนั้น เนื่องจากฟังก์ชันความเป็นไปได้ (likelihood function) ในสมการที่ 10 มีค่าสูงสุดเมื่อพารามิเตอร์$\\theta$ มีค่าเท่ากับ $\\hat{\\theta}_{MLE}$ ดังนั้น ฟังก์ชันความเป็นไปได้ (likelihood function) ในสมการที่ 11 จะมีค่าสูงสุด ถ้าพารามิเตอร์$\\gamma$ มีค่าเท่ากับ $\\hat{\\gamma}_{MLE}$ ที่ทำให้ $\\hat{\\theta}_{MLE} = g^{-1}(\\hat{\\gamma}_{MLE})$ นั่นคือ $ \\hat{\\gamma}_{MLE} = g(\\hat{\\theta}_{MLE}) $\n",
    "\n",
    "- ส่วนในกรณีที่ฟังก์ชัน g ไม่ใช่ฟังก์ชันหนึ่งต่อหนึ่ง ก็สามารถพิสูจน์ได้ด้วยวิธีการที่คล้ายคลึงกัน แต่ต้องตระหนักว่าสิ่งที่ต้องการคือค่าที่ต้องการนำไปสู่ค่าสูงสุด ถึงแม้ว่า อาจจะมีค่าพารามิเตอร์ที่ทำให้ได้ค่าสูงสุดหลายค่า\n",
    "\n",
    "### ตัวอย่าง: คุณสมบัติไม่แปรเปลี่ยน (invariance property) ของตัว ประมาณค่าด้วยความเป็นไปได้สูงสุด (MLE)\n",
    "\n",
    "**Example**\n",
    "\n",
    "สมมุติให้$X_1, . . . , X_n$ เป็นกลุ่มตัวอย่างสุ่มที่เลือกมาการแจกแจงแบบเอกรูป (uniform distribution) ในช่วง $[0,c]$ เช่นเดียวกับตัวอย่างที่แล้วซึ่งพิสูจน์แล้วว่า ตัวประมาณค่า ด้วย ความเป็นไปได้สูงสุด (MLE) ของ c มีค่าเท่ากับ$ \\hat{c}_{MLE} = max(X_1, . . . , X_n)$ เราสามารถประยุกต์ใช้คุณสมบัติไม่แปรเปลี่ยน (invariance property) เพื่อหา ตัวประมาณค่า ของความแปรปรวน (variance) ของ X ได้โดยเริ่มจากการที่ทราบว่า$Var [X] = \\frac {c^2}{12}$ ในขณะ เดียวกันเราก็ทราบว่า ตัวประมาณค่า $\\hat{c}_{MLE}= max(X_1, . . . , X_n)$ ดังนั้น\n",
    "\n",
    "$$\\hat{Var}[X] = \\frac{\\hat{C}^2_{MLE}}{12} = \\frac{max(x_1,\\dots,x_n)^2}{12}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ความคงเส้นคงวา (consistency) ของตัวประมาณค่าด้วยความเป็นไปได้ สูงสุด (MLE)\n",
    "\n",
    "- คุณสมบัติอันหนึ่งที่สำคัญของ ตัวประมาณค่า ด้วยความเป็นไปได้สูงสุด (MLE) คือ ความ คงเส้นคงวา (consistency) นั่นคือ เมื่อ กลุ่มตัวอย่างมีขนาดใหญ่มากพอ แล้ว ตัว ประมาณค่าด้วยความเป็นไปได้สูงสุด (MLE) จะมีค่าใกล้เคียงกับค่าที่แท้จริง\n",
    "\n",
    "- ทฤษฎีบทและการพิสูจน์ด้านล่างนี้ดัดแปลงมาจาก Hogg et al.(2005) โดยเริ่มจากการ กำหนดเงื่อนไขปกติ (regularity conditions) ต่อไปนี้ \n",
    "\n",
    "  RC1 ฟังก์ชันความหนาแน่นของความน่าจะเป็น (p.d.f.) $f(x, \\theta)$ แตกต่างกันชัดเจน หมายความ ว่า ถ้า$ \\theta\\ne\\theta′$ แล้ว $f(x,\\theta)\\ne f(x,\\theta′)$\n",
    "  \n",
    "  RC2 ฟังก์ชันความหนาแน่นของความน่าจะเป็น (p.d.f.) $f(x,\\theta)$ มีส่วนค้ำจุน (support) S เหมือนกันสำหรับทุกๆ ค่าพารามิเตอร์$\\theta$\n",
    "  \n",
    "  RC3 ค่าที่แท้จริง $\\theta_0$ ของพารามิเตอร์$\\theta$ เป็น จุดภายใน (interior point) ของเซ็ต$\\Theta$\n",
    "  \n",
    "## ทฤษฎี: ความคงเส้นคงวา (consistency) ของตัวประมาณค่าด้วยความ เป็นไปได้สูงสุด (MLE)\n",
    " \n",
    " **Theorem**\n",
    " \n",
    "สมมุติว่าตัวแปรสุ่ม $X_1,\\dots, X_n$ สอดคล้องกับเงื่อนไขปกติ (regularity conditions) RC1 - RC3 โดยที่ $\\theta_0$ เป็นค่าพารามิเตอร์ที่แท้จริง (true parameter) และ $f(x|\\theta)$ สามารถหาค่าอนุพันธ์ เทียบกับ $\\theta$ ได้ แล้ว คำตอบของสมการความเป็นไปได้ (likelihood equation) $\\hat{\\theta}$ ซึ่งสอดคล้อง กับสมการต่อไปนี้\n",
    "$$ \\frac{ \\partial\\log L(\\hat{\\theta}|X)}{ \\partial\\theta}  = 0 ---------(12) $$\n",
    "\n",
    "จะมีความคงเส้นคงวา (consistent) นั่นคือ $ \\hat{\\theta}  \\rightarrow^p \\theta_0 $\n",
    "\n",
    "### ตัวอย่าง: ความคงเส้นคงวา (consistency) ของตัวประมาณค่าด้วยความ เป็นไปได้สูงสุด (MLE)\n",
    "\n",
    "**Example**\n",
    "\n",
    "พิจารณาตัวอย่าง $X_1,\\dots, X_n$ โดยที่ $X_i$ มีการแจกแจงแบบเบอร์นูลลี (Bernoulli distribution) สำหรับพารามิเตอร์ $\\theta$ ดังนั้นตัว ประมาณค่าด้วยความเป็นไปได้สูงสุด (MLE)\n",
    "\n",
    "$$ \\hat{\\theta}_{MLE}(X) = \\frac {\\sum_{i=1}^{n}X_i}{n} = \\bar X_n ---------(13) $$\n",
    "\n",
    "- เราสุ่มตัวอย่างจาก การแจกแจงแบบเบอร์นูลลี (Bernoulli distribution) โดยกำหนดพารามิเตอร์$\\theta$ = 0.4 แล้ว นำข้อมูล จากการสุ่มนั้นมาประมาณพบว่า\n",
    "\n",
    "<img src=\"images/13.4.png\" width=400 align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## บทนำ: การประมาณค่าด้วยโมเมนต์ (Method of Moments)\n",
    "\n",
    "- การประมาณค่าด้วยโมเมนต์ (method of moments หรือเรียกสั้นๆ ว่า MM) เป็นวิธี ประมาณค่าอย่างง่ายที่อาศัยหลักการพื้นฐานที่ว่า ค่าคาดหมายจากตัวอย่าง (sample mean) $\\bar X_n$ คือตัวประมาณค่า (estimator) ที่ดีสำหรับค่าคาดหมาย (population mean) $E[X]$ ซึ่งเป็นหลักการที่ประยุกต์ใช้อย่างกว้างขวาง แม้แต่ในกรณีของการประมาณ ค่าที่ซับซ้อน\n",
    "\n",
    "- ข้อดีอีกอย่างหนึ่งของการประมาณค่าด้วยโมเมนต์ (MM) ก็คือการที่สามารถหาตัวประมาณ ค่า (estimator) ได้ค่อนข้างแน่นอน ซึ่งต่างจากวิธีการประมาณค่าด้วยความเป็นไปได้สูงสุด (Maximum Likelihood Estimation หรือเรียกสั้นๆ ว่า MLE) ที่อาจจะไม่สามารถหาตัว ประมาณค่าได้ (estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### การประมาณค่าด้วยโมเมนต์ (Method of Moments)\n",
    "\n",
    "- กำหนดให้$X_1,\\dots, X_n$ เป็น ตัวอย่างที่สุ่มมาจากประชากร ที่มีฟังก์ชันความหนาแน่นของ ความน่าจะเป็น (p.d.f.) หรือฟังก์ชันความน่าจะเป็น (p.f.)$ f(x|\\theta_1,\\dots, \\theta_k)$\n",
    "\n",
    "- วิธีการประมาณค่าด้วยโมเมนต์ (MM) ของพารามิเตอร์$\\theta = (\\theta_1,\\dots, \\theta_k)$ เริ่มได้ด้วยการ กำหนดให้k โมเมนต์จากตัวอย่าง (sample moments) มีค่าเท่ากับ k โมเมนต์จาก ประชากร (population moments) ซึ่งเป็นฟังก์ชันของพารามิเตอร์$\\theta$\n",
    "\n",
    "- ผลลัพธ์จากขั้นตอนนี้คือ ระบบสมการของ k สมการที่มีตัวไม่ทราบค่า (unknown) ทั้งหมด k ตัว ขั้นตอนสุดท้ายคือการแก้ระบบสมการนี้ โดยที่ผลลัพธ์ที่ได้จะอยู่ในรูปของฟังก์ชัน $\\theta_i (X_1,\\dots, X_n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### โมเมนต์จากตัวอย่าง (sample moments)\n",
    "\n",
    "- กำหนดให้$M_j = \\frac{1}{n}\\sum_{i=1}^{n}X^j_i$ แทน โมเมนต์จากตัวอย่าง (sample moments) อันดับที่ $j = 1, . . . ,k$ และ $\\mu_j (\\theta_1,\\dots,\\theta_k) = E[X^j ]$ แทน โมเมนต์จากประชากร (population moments) อันดับที่ j = 1, . . . ,k\n",
    "\n",
    "- การประมาณค่าด้วยโมเมนต์ (MM) คือการแก้ระบบสมการต่อไปนี้ \n",
    "$$ \\frac{1}{n} \\sum_{i=1}^{n} X_i = \\mu_1(\\theta_1,\\dots,\\theta_k) ---------(14) $$\n",
    "$$ \\frac{1}{n} \\sum_{i=1}^{n} X_i^2 = \\mu_2(\\theta_1,\\dots,\\theta_k) ---------(15) $$\n",
    " $$\\vdots $$\n",
    "$$ \\frac{1}{n} \\sum_{i=1}^{n} X_i^k = \\mu_k(\\theta_1,\\dots,\\theta_k) ---------(17) $$\n",
    "\n",
    "- นี่คือระบบสมการที่มีทั้งหมด k สมการและมีตัวไม่ทราบค่าทั้งหมด k ตัว "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ตัวอย่าง: การประมาณค่าด้วยโมเมนต์ (Method of Moments)\n",
    "\n",
    "**Example**\n",
    "\n",
    "สมมุติว่า เป็นตัวอย่างสุ่มที่มีมีการแจกแจงเหมือนกันและเป็นอิสระต่อกัน (i.i.d.) แบบปกติN $(\\mu, \\sigma^2 )$ นั่นคือ พารามิเตอร์ที่ต้องการทราบค่าในตัวอย่างนี้มีทั้งหมด 2 ตัวคือ $\\theta_1 = \\mu \\theta_2 = \\sigma^2$\n",
    "\n",
    "- เราจำเป็นต้องใช้โมเมนต์ที่หนึ่งและโมเมนต์ที่สอง\n",
    "$$ \\frac{1}{n}\\sum_{i=1}^{n}X_i = \\mu , \\frac{1}{n}\\sum_{i=1}^{n}X_i^2  = E[X^2] = \\sigma^2 + \\mu^2$$\n",
    "\n",
    "- ตัวประมาณค่าด้วยโมเมนต์ (MM estimators) ในกรณีนี้เท่ากับ\n",
    "$$ µ = \\frac{1}{n}\\sum_{i=1}^{n}X_i  \\equiv \\bar X , \\sigma^2 = \\frac{1}{n}\\sum_{i=1}^{n}(X_i - \\bar X)^2 $$\n",
    "\n",
    "- ตัวประมาณค่าสำหรับค่าคาดหมายและค่าความแปรปรวนที่ใช้กันอยู่ทั่วไป อาจจะแตกต่างบ้างเล็กน้อยในกรณี ของค่าความแปรปรวนที่หารด้วย n ไม่ใช่n – 1\n",
    "\n",
    "- ความแตกต่างตรงนี้มีผลต่อความเบี่ยงเบน (bias) ของตัวประมาณค่าในทางทฤษฎี แต่ในทางปฏิบัติหาก n มีค่า มากพอแล้ว ค่าประมาณที่ได้จะมีค่าใกล้เคียงกันมาก\n",
    "\n",
    "### การประมาณค่าด้วยโมเมนต์ (Method of Moments)\n",
    "\n",
    "- อย่างไรก็ตาม วิธีการประมาณค่าด้วยโมเมนต์ (MM) ก็มีจุดอ่อน ทั้งนี้ส่วนหนึ่งเป็นเพราะ โมเมนต์เพียงไม่กี่อันอาจจะไม่สามารถบอกคุณสมบัติของการแจกแจงได้ดีพอ เพราะหาก ต้องการให้ครอบคลุมทั้งหมดต้องใช้โมเมนต์ทุกอัน \n",
    "- ทฤษฎีบทต่อไปนี้สรุปว่า ตัวประมาณค่าด้วยโมเมนต์ (MM) มีความคงเส้นคงวา (consistent) นั่นคือ เมื่อจำนวนตัวอย่างมากพอแล้ว ค่าประมาณด้วยโมเมนต์ (MM) จะมี ค่าใกล้เคียงกับค่าพารามิเตอร์ที่แท้จริง (true parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ทฤษฎี: ความคงเส้นคงวา (consistency) ของการประมาณค่าด้วยโมเมนต์ (Method of Moments)\n",
    "\n",
    "**Theorem**\n",
    "\n",
    "สมมุติว่าตัวแปรสุ่ม $X_{1}, . . . , X_{n}$ ที่เป็นอิสระตอกันและมีการแจกแจงเหมือนกัน (i.i.d.) โดยมี $\\theta _{0}$ เป็นค่าพารามิเตอร์ที่แท้จริง (true parameter) ซึ่งมีทั้งหมด k ตัว \n",
    "\n",
    "และสมมุติว่า k โมเมนต์ของ การแจกแจงหาค่าได้และมีค่าจำกัด แล้ว ตัวประมาณค่าด้วยโมเมนต์ (MM) จะมีความคงเส้นคงวา (consistent) นั่นคือ $\\hat{\\theta } \\overset{p}{\\rightarrow} \\theta _{0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### การพิสูจน์: ความคงเส้นคงวา (consistency) ของการประมาณค่าด้วยโมเมนต์ (Method of Moments)\n",
    "\n",
    "**Proof.**\n",
    "\n",
    "กฎว่าด้วยตัวอย่างขนาดใหญ่ (Law of Large Numbers) ทำให้สรุปได้ว่า สำหรับค่าจำนวนเต็ม 0 < j ≤ k\n",
    "\n",
    "$$plim M_{j} = plim \\frac{1}{n} \\sum_{i=1}^{n} X_{i}^{j}= E [X_{i}^{j}]$$\n",
    "\n",
    "ซึ่งมีค่าเท่ากับ $µ_{j} (\\theta _{0})$ในขณะเดียวกัน เมื่อเราประยุกต์ใช้การลู่เข้าเชิงความน่าจะเป็นกับระบบสมการที่ (15)-(18) จะสามารถสรุปได้ว่า\n",
    "\n",
    "$$plim M_{j} = plim µ_{j}(\\hat{\\theta })= µ_{j}(plim \\hat{\\theta})$$\n",
    "\n",
    "ดังนั้นเราจึงสามารถสรุปได้ว่า\n",
    "\n",
    "$$µ_{j}(plim \\hat{\\theta }) = µ_{j} (\\theta_{0}) ⇒ plim \\hat{\\theta} = \\theta_{0}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ตัวอย่างความคงเส้นคงวา (consistency) ของการประมาณค่าด้วยโมเมนต์\n",
    "\n",
    "จากตัวอย่างที่แล้ว ถ้าเราสุ่มตัวอย่างที่มีมีการแจกแจงเหมือนกันและเป็นอิสระต่อกัน (i.i.d.) แบบปกติ $N(\\mu, \\sigma^2)$ดังนั้น ตัวประมาณค่าด้วยโมเมนต์ (MM estimators) ในกรณีนี้เท่ากับ\n",
    "\n",
    "$$\\mu = \\frac{1}{n} \\sum_{i=1}^{n} X_{i} \\equiv \\bar{X} \\ ,\\ \\sigma^2 = \\frac{1}{n} \\sum_{i=1}^{n} (X_{i}-\\bar{X})^2$$\n",
    "\n",
    "* ถ้าตัวอย่างที่สุ่ม คือ การแจกแจงเหมือนกันและเป็นอิสระต่อกัน (i.i.d.) แบบปกติ ที่มี$\\mu$ = 50 และ $σ^2$ = 50\n",
    "\n",
    "<img src=\"images/13.5.jpg\" width=500 align=\"center\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
