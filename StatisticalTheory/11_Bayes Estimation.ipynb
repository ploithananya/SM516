{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>หลักการประมาณแบบเบส์ (Bayes Estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## บทนำ\n",
    "\n",
    "* หลักการพื้นฐานของการประมาณค่า (estimation) โดยพิจารณาวิธีการประมาณค่าทั้งหมด 3 วิธี\n",
    "    - **วิธีการประมาณค่าแบบเบส์ (Bayes Estimation)**\n",
    "    - วิธีการประมาณค่าด้วยความเป็นไปได้สูงสุด (Maximum Likelihood Estimation: MLE)\n",
    "    - วิธีการประมารค่าด้วยโมเมนต์ (Method of Moment: MM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## นิยาม: พารามิเตอร์ (Parameter)\n",
    "\n",
    "**<u>Definition</u>**\n",
    "พารามิเตอร์ (parameter) $\\theta \\in \\Theta$ หมายถึงลักษณะเฉพาะ (characteristics) ที่กำหนดการแจกแจงร่วม (joint distribution) ของตัวแปรสุ่มที่สนใจ โดยเรียกเซ็ต $\\Theta$ ว่าปริภูมิพารามิเตอร์ (parameter space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## นิยาม: แบบจำลองทางสถิติ (Statistical Model)\n",
    "\n",
    "**<u>Definition</u>**\n",
    "แบบจำลองทางสถิติ (statistical model) ประกอบไปด้วย\n",
    "\n",
    "* การระบุอย่างขัดเจนว่า **\"ตัวแปรสุ่มที่สนใจมีอะไรบ้าง ทั้งที่สามารถสังเกตได้  (observable) และไม่สามารถสังเกตได้ (unobservable)** แต่กำหนดให้มีอยู่ในทางทฤษฎี เช่น รายได้ อัตราดอกเบี้ย หรืออัตราผลตอบแทนสุทธิของสินทรัพย์ต่างๆ\n",
    "\n",
    "\n",
    "* **\"ข้อกำหนดหรือสมการที่บอกถึงความสัมพันธ์ระหว่างตัวแปรสุ่มที่สนใจ\"** โดยอาจอยู่ในรูปของการแจกแจงร่วม  (joint distribution) สำหรับตัวแปรสุ่มที่สามารถสังเกตได้  (observable random variables)\n",
    "\n",
    "\n",
    "* **\"การระบุค่าของพารามิเตอร์ (parameter identification) $\\theta$\"** ที่ทำหน้าที่กำหนดการแจกแจงร่วม (joint distribution) ของตัวแปรสุ่มที่สนใจ โดยในส่วนนี้จะมองว่า **พารามิเตอร์ที่ไม่ทราบค่า (unknown parameters) เป็นค่าคงที่** นั่นคือ สิ่งที่ต้องการทราบค่าเป็นจำนวนจริงหรือจุด ทำให้เรียกการประมาณค่าแบบนี้ว่า **การประมาณค่าแบบจุด (point estimation)** ส่วนการแจกแจงร่วมของตัวแปรสุ่มที่สามารถสังเกตได้ (observable random variables) ก็จะพิจารณาเป็นการแจกแจงร่วมแบบมีเงื่อนไข (joint conditional probability) สำหรับค่าที่เกิดขึ้นจริง (realized value) ของ $\\theta$ นั่นคือ *$f(x|\\theta)$*\n",
    "\n",
    "\n",
    "* สำหรับกรณีที่ **\"สมมติให้พารามิเตอร์ $\\theta$ เป็นตัวแปรสุ่ม\"** สิ่งที่จำเป็นสำหรับแบบจำลองทางสถิติอีกอย่างหนึ่ง คือ **การกำหนดรูปแบบการแจกแจงร่วม (joint distribution) ของพารามิเตอร์ที่ไม่ทราบค่า (unknown parameters)** ส่วนการแจกแจงร่วมของตัวแปรสุ่มที่สามารถสังเกตได้ (observable random variables) ก็จะพิจารณาเป็นการแจกแจงร่วมแบบมีเงื่อนไข (joint conditional probability) สำหรับค่าที่เกิดขึ้นจริง  (realized value) ของ $\\theta$ นั่นคือ *$f(x|\\theta)$* เช่นเดียวกับกรณีก่อนหน้านี้\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## นิยาม: การอนุมานทางสถิติ (Statistical Inference)\n",
    "\n",
    "* โดยทั่วไป เราจำเป็นจะต้องประมาณค่าพารามิเตอร์เพราะ เราต้องการ **ทดสอบสมมติฐาน (hypothesis testing)** ที่ต้องการทราบ\n",
    "* การทดสอบสมมติฐานจะอยู่ในรูปของข้อความเชิงความน่าจะเป็น (probabilistic statement) ที่เรียกอย่างเป็นทางการว่า **การอนุมานทางสถิติ  (statistical inference)**\n",
    "* ยกตัวอย่างเช่น เราอาจจะสนใจว่า สามารถบอกด้วยความมั่นใจแค่ไหนว่าค่าพารามิเตอร์ $\\theta$ มีค่ามากกว่าศูนย์ นั่นคือ ต้องการทดสอบสมมติฐานที่ว่า *$\\theta > 0$* เป็นต้น\n",
    "\n",
    "**<u>Definition</u>**\n",
    "การอนุมานทางสถิติ (statistical inference) คือกระบวนการ (procedure) ที่สร้างข้อความเชิง\n",
    "ความน่าจะเป็น (probabilistic statement) ที่เกี่ยวข้องกับแบบจำลองทางสถิติ (statistical model)\n",
    "\n",
    "### รูปแบบของการอนุมานทางสถิติ\n",
    "\n",
    "การอนุมานทางสถิติ (Statistical Inference) แบ่งได้เป็น 4 รูปแบบดังนี้\n",
    "* **1. การคาดการณ์ (prediction)** เป็นคาดเดาค่าตัวแปรสุ่มหรือฟังก์ชันของตัวแปรสุ่มที่ยังไม่ทราบค่า\n",
    "    - ตัวอย่างเช่น การคาดการณ์ค่าเฉลี่ยของผลตอบแทนของกองทุนรวมในปีหน้ามีค่าเท่ากับเท่าใด? การคากการณ์ผลิตภัณฑ์มวลรวม (GDP) ของประเทศในปีหน้าจะขยายตัวร้อยละเท่าใด? หรือ  การคาดการณ์ว่าในปีหน้าจะมีเด็กที่มีพัฒนาช้ากว่าวัยร้อยละเท่าใด?\n",
    "    - เรามักเรียกการคาดการณ์ในกรณีที่สิ่งที่ต้องคาดการณ์หรือพยากรณ์ว่า การประมาณค่า (estimation) ซึ่งคือประเด็นหลักของบทนี้\n",
    "    \n",
    "    \n",
    "* **2. การออกแบบการทดลอง (experimental design)**\n",
    "เป็นการกำหนดว่าควรจะเก็บข้อมูลอย่างไรและมากน้อยเพียงใด รวมทั้งรูปแบบการทดลอง\n",
    "    - ตัวอย่างเช่น การทดลองแบบสุ่ม (randomized controlled trials) ที่ดีควรจะมีการ\n",
    "ออกแบบจำนวนกลุ่มตัวอย่างที่เหมาะสม เพื่อให้มั่นใจได้ว่าการทดสอบสมมุติฐานที่จะดำเนินการมีอำนาจทางสถิติ (statistical power) มากเพียงพอ\n",
    "\n",
    "\n",
    "* **3. ปัญหาการตัดสินใจทางสถิติ (statistical decision problems)**\n",
    "หมายถึงกระบวนการตัดสินใจที่ผลที่ตามมาขึ้นอยู่กับค่าของพารามิเตอร์ที่ไม่ทราบค่า (แต่ต้องใช้ข้อมูลและเครื่องมือทางสถิติประมาณค่า) เพื่อให้สามารถตัดสินใจได้อย่างมีหลักการ จึงจำเป็นจะต้องพยายามประมาณค่าพารามิเตอร์ดังกล่าว\n",
    "    - โดยธรรมชาติแล้ว เราไม่มีทางที่จะแน่ใจได้ว่าพารามิเตอร์ดังกล่าวมีค่าเท่าใดกันแน่ แต่เป็นไป\n",
    "ได้ที่จะทราบการแจกแจงของพารามิเตอร์ ดังนั้น การตัดสินใจในกรณีนี้จึงต้องทำภายใต้\n",
    "เงื่อนไขเชิงความน่าจะเป็น ซึ่งขึ้นอยู่กับ **การแจกแจงของตัวประมาณค่า (distribution of\n",
    "estimators)**\n",
    "\n",
    "    - ยกตัวอย่างเช่น เราจะตัดสินใจซื้อกองทุนรวม A ถ้าคาดว่าอัตราผลตอบแทนไม่น้อยกว่าร้อยละ 3 ดังนั้น ปัญหาทางสถิติในกรณีนี้ คือ ความน่าจะเป็นที่อัตราผลตอบแทนของกองทุน A จะมีค่าไม่น้อยกว่าร้อยละ 3 มีค่าเท่าใด?\n",
    "    - วิธีการอนุมานทางสถิติ (statistical inference)  แบบนี้เกี่ยวข้องกับสิ่งที่เรียกว่า **การทดสอบสมมุติฐาน (hypothesis testing)**\n",
    "    \n",
    "    \n",
    "* **4. การอนุมานทางสถิติแบบอื่นๆ** ที่ไม่สามารถจัดอยู่ในสามประเภทแรกได้"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## นิยาม: ตัวประมาณค่า (Estimator)\n",
    "\n",
    "**<u>Definition</u>**\n",
    "\n",
    "กำหนดให้ $x_1, . . . ,x_n$ เป็นตัวอย่าง (sample) ที่สุ่มมาจากากรแจกแจงร่วมกำหนดที่มีพารามิเตอร์ $\\theta ∈ \\Theta$ เราเรียกฟังก์ชันจำนวนจริง $\\hat{\\theta}(x_1, . . ., x_n)$ ว่า ตัวประมาณค่า (estimator) ของพารามิเตอร์ $\\theta$\n",
    "\n",
    "นอกจากนี้ เราจะเรียก $\\hat{\\theta}(x_1, . . ., x_n)$ ว่าค่าประมาณ (estimate) ของพารามิเตอร์ $\\theta$ เมื่อประมาณค่าด้วยข้อมูล $x_1, . . . ,x_n$ ซึ่งเป็นค่าที่เกิดขึ้นจริง (realized value) ของ $x_1, . . . ,x_n$\n",
    "\n",
    "* ในขณะเดียวกัน เรามักเรียกฟังก์ชันของตัวอย่าง $\\hat{\\theta}(x_1, . . ., x_n)$ ว่าค่าสถิติ (statistic) ดังนั้น จึงอาจสรุปได้ว่า **\"ตัวประมาณค่า (estimator) ก็คือค่าสถิติ (statistic) อย่างหนึ่ง\"** นั่นเอง"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## นิยาม: : ฟังก์ชันความน่าจะเป็นก่อนการสังเกต (Prior P.F.)\n",
    "\n",
    "**<u>Definition</u>**\n",
    "\n",
    "กำหนดให้ $\\theta$ คือพารามิเตอร์ที่ไม่ทราบค่า ซึ่งสมมติให้เป็นตัวแปรสุ่ม การแจกแจงก่อนการสังเกต (prior distribution) คือการแจกแจง (distribution) ของพารามิเตอร์ $\\theta$ ที่กำหนดขึ้นก่อนที่จะสังเกตค่าของตัวแปรสุ่มอื่นๆ ซึ่งมักแทนด้วยฟังก์ชันความหนาแน่นของความน่าจะเป็นก่อนการสังเกต (prior p.d.f.) หรือฟังก์ชันความน่าจะเป็นก่อนการสังเกต (prior p.f.) h($\\theta$)\n",
    "\n",
    "### ตัวอย่าง: ฟังก์ชันความน่าจะเป็นก่อนการสังเกต (Prior P.F.)\n",
    "\n",
    "**<u>Example</u>**\n",
    "กำหนดให้ $\\theta$ แทนความน่าจะเป็นที่จะได้ผลการโยนเหรียญเป็นหัว ซึ่งในที่นี้เป็น**พารามิเตอร์ของแบบจำลองทางสถิติ**ที่สนใจ สมมติว่าเหรียญหนึ่งอาจจะเป็นเหรียญที่ด้านหนึ่งเป็นหัว สว่นอีกด้านหนึ่งเป็นก้อย หรืออาจจะเป็นเหรียญที่มีแต่หัวทั้ง 2 ด้าน\n",
    "\n",
    "* จากการสมมติดังกล่าว $\\theta$ เป็นไปได้ 2 ค่า คือ $ \\theta = \\frac{1}{2}$ และ $\\theta = 1$\n",
    "\n",
    "* **การแจกแจงก่อน (prior distribution)** สำหรับกรณีนี้คือการแจกแจงของ $\\theta$ คือ $ h(\\theta = \\frac{1}{2}) = 0.6$ และ $ h(\\theta = 1) = 0.4$\n",
    "\n",
    "* สังเกตว่า h ต้องรวมแล้ว **เท่ากับ 1** เพราะเป็นฟังก์ชันความน่าจะเป็นก่อนการสังเกต (Prior P.F.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## นิยาม: ฟังก์ชันความน่าจะเป็นหลังการสังเกต (Posterior P.F.)\n",
    "\n",
    "**<u>Definition</u>**\n",
    "\n",
    "กำหนดให้ $\\theta$ คือพารามิเตอร์ที่ไม่ทราบค่า ซึ่งสมมติให้เป็นตัวแปรสุ่มและ $x_1, . . . ,x_n$ เป็นตัวอย่าง (sample) ซึ่งพิจารณาว่าเป็นตัวแปรสุ่ม การแจกแจงหลังการสังเกต (Posterior distribution) คือ การแจกแจงแบบมีเงื่อนไขของ $\\theta$ เมื่อทราบค่า $X_1=x_1, X_2=x_2, . . . , X_n=x_n$ ซึ่งมักแทนด้วยฟังก์ชันความหนาแน่นของความน่าจะเป็นหลังกานสังเกต (posterior p.d.f.) หรือฟังก์ชันความน่าจะเป็นหลังกานสังเกต (posterior p.f.) $h(\\theta|x)$\n",
    "\n",
    "* สังเกตว่าความแตกต่างเชิงสัญลักษณ์ระหว่างการแจกแจงก่อนการสังเกต (prior distribution) $h(\\theta)$ และการแจกแจงหลังการสังเกต (posterior distribution) $h(\\theta|x)$ คือ **“การที่อันแรกไม่มีเงื่อนไขแต่อันหลังเป็นการแจกแจงแบบมีเงื่อนไข”**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ทฤษฎี: การแปลงการแจกแจงก่อนการสังเกต (prior distribution) ให้เป็นการแจกแจงหลังการสังเกต (posterior distribution)\n",
    "\n",
    "* เป็นการประยุกต์ใช้้ทฤษฎีบทของเบส์ เพื่อแปลงการแจกแจงก่อนการสังเกต (prior distribution) ให้เป็นการแจกแจงหลังการสังเกต (posterior distribution) โดยอาศัยสารสนเทศ (information)ที่ได้จากข้อมูล(data) $x = (x_1, . . ., x_n)$\n",
    "\n",
    "* ประเด็นทางเทคนิคที่สำคัญในที่นี้คือหลักการที่ว่า  ข้อมูลที่ได้มานั้นมาจากการสุ่มจากการแจกแจงแบบมีเงื่อนไข (conditional distribution) ที่ถูกกำหนดโดยพารามิเตอร์ $\\theta$ ซึ่งแทนด้วย $f(x|\\theta)$\n",
    "\n",
    "**<u>Theorem</u>**\n",
    "\n",
    "กำหนดให้ $x_1, . . ., x_n$ คือตัวอย่างสุ่มที่เกิดจากการสุ่มเลือกจากการแจกแจง $f(x|\\theta)$ และกำหนดให้ $h(\\theta)$ แทนการแจกแจงก่อนการสังเกต (prior distribution) ของ $\\theta$ แล้ว ฟังก์ชันความหนาแน่นของความน่าจะเป็นหลังการสังเกต (posterior p.d.f.) หรือฟังก์ชันความน่าจะเป็นหลังการสังเกต (posterior p.f.) เท่ากับ\n",
    "\n",
    "<div align=\"right\">(1)</div>\n",
    "$$ h(\\theta|x) = \\frac{f(x_1|\\theta . . . f(x_n|\\theta)h(\\theta)}{\\int_{\\tilde \\theta \\in \\Theta} f(x|\\tilde \\theta) h(\\tilde \\theta) d\\tilde \\theta} ,สำหรับ \\theta \\in \\Theta$$\n",
    "\n",
    "\n",
    "**<u>Proof.</u>**\n",
    "* จากนิยามของการแจกแจงแบบมีเงื่อนไข เราสามารถเขียนได้ว่า\n",
    "\n",
    "$$ h(\\theta|x) = \\frac{f(x,\\theta)}{g(x)} ,สำหรับ \\theta \\in \\Theta$$\n",
    "\n",
    "โดยที่ g(x) แทนฟังก์ชันความหนาแน่นของความน่าจะเป็นตามขอบ (marginal p.d.f.) ซึ่งมีค่าเท่ากับ\n",
    "\n",
    "$$ g(x) = \\int_{\\tilde \\theta\\in \\Theta} f(x|\\tilde \\theta) h(\\tilde \\theta) d\\tilde \\theta $$\n",
    "\n",
    "ส่วนตัวตั้งสามารถเขียนใหม่ได้เป็น\n",
    "\n",
    "$$ f(x,\\theta) = f(x|\\theta)h(\\theta)$$\n",
    "\n",
    "ในขณะเดียวกัน การที่ x_1, . . ., x_n เป็นตัวอย่างสุ่ม สามารถเขียน $f(x|\\theta)$ ได้เป็น\n",
    "\n",
    "$$ f(x|\\theta) = f(x_1|\\theta) . . . f(x_n|\\theta)$$\n",
    "\n",
    "ดังนั้น จึงสามารถสรุปได้ว่า\n",
    "\n",
    "$$ h(\\theta|x) = \\frac{f(x_1|\\theta) . . . f(x_n|\\theta)h(\\theta)}{\\int_{\\tilde \\theta \\in \\Theta} f(x|\\tilde \\theta) h(\\tilde \\theta) d\\tilde \\theta} ,สำหรับ \\theta \\in \\Theta $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## การแปรผันตามส่วน (proportionality) ของการแจกแจงหลังการสังเกต (posterior distribution)\n",
    "\n",
    "* ประเด็นที่น่าสังเกตอันหนึ่งคือ **ตัวหารในสมการที่1 ไม่ขึ้นอยู่กับพารามิเตอร์ θ** θ เพราะได้อินทิเกรต θ ออกไปหมดแล้วและอันที่จริงพจน์นี้ทำหน้าที่เป็นเพียงแค่ค่าคงที่ที่ทำให้การแจกแจงหลังการสังเกต (posterior distribution) มีคุณสมบัติที่เหมาะสม ซึ่งในที่นี้หมายถึงการที่ผลรวมหรือผลการอินทิเกรตของการแจกแจงหลังการสังเกต (posterior distribution) มีค่าเท่ากับหนึ่งนั่นเอง\n",
    "\n",
    "* บางครั้งเราอาจจะมองข้ามพจน์นี้ไปได้และเขียน $$h(\\theta|x)$$ ในรูปของการแปรผันตามส่วน (proportionality) ได้เป็น\n",
    "\n",
    "<div align=\"right\">(2)</div>\n",
    "$$ h(\\theta|x) ∝ f(x_1|\\theta) . . . f(x_n|\\theta) h(\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ตัวอย่าง : การประยุกต์การแปรผันตามส่วนของการแจกแจงหลังการสังเกต (Posterior Distribution)\n",
    "\n",
    "**<u>Example</u>**\n",
    "กำหนดให้ $θ$ แทนสัดส่วนของสินค้าที่มีตำหนิ(defective items) ที่ยังไม่ทราบค่าและการแจกแจงก่อนการสังเกต(prior distribution) เป็นแบบเอกรูป(uniform distribution) ในช่วง $[0,1]$ สิ่งที่ต้องการทราบ คือ การแจกแจงหลังการสังเกต(posterior distribution) ของ $θ$ หลังจากสุ่มตรวจสินค้าทั้งหมด $n$ ชิ้น\n",
    "\n",
    "* กำหนดให้ $X_i$ แทนผลการตรวจสินค้าชิ้นที่ $i = 1,...,n$ โดยที่ $X_i = 1$ ถ้าสินค้าที่ $i$ มีตำหนิไม่เช่นนั้นจะมีค่าเท่ากับศูนย์ นั่นคือ $X_i$ มีการแจกแจงแบบเบอร์นูลลีซึ่งมีฟังก์ชันความน่าจะเป็น(p.f.) เท่ากับ\n",
    "\n",
    "$$ f(x_i|θ) = \\begin{Bmatrix}\n",
    "θ^{x_i}(1-θ)^{1-x_i}, สำหรับ x_i =0,1\\\\\n",
    "0, ถ้าเป็นอย่างอื่น\\\\\n",
    "\\end{Bmatrix}$$\n",
    "\n",
    "* การที่ตัวอย่างที่ได้มาเป็นตัวอย่างสุ่ม(random sample) ทำให้สามารถเขียนได้ว่า\n",
    "\n",
    "<center>$f(x_1 \\mid θ)···f(x_n \\mid θ) =$ $\\prod_{i=1}^{n}$ $θ^{x_i}$ $(1 - θ)^{1 - x_i} =$ $θ$$\\sum_{i=1}^{n}$$x_i$ (1-θ)^(n-$\\sum_{i=1}^{n})$ $x_i =$ $θ^y (1 - θ)^{n - y}$\n",
    "\n",
    "โดยที่ $y =$ $\\sum_{i=1}^{n}$ $x_i$ ส่วนการที่การแจกแจงก่อนการสังเกต(prior distribution) เป็นแบบเอกรูป(uniform distribution) ในช่วง $[0,1]$ ทำให้เขียนได้ว่า $h(θ) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### วิธีทำ : การประยุกต์การแปรผันตามส่วนของการแจกแจงหลังการสังเกต (posterior distribution)\n",
    "\n",
    "**<u>Example</u>**\n",
    "\n",
    "* ดังนั้นการแจกแจงหลังการสังเกต (posterior distribution) ของ $θ$ เท่ากับ\n",
    "\n",
    "$$h(θ \\mid x) ∝ θ^y (1−θ)^{n−y}$$\n",
    "\n",
    "* เมื่อพิจารณาให้ดีแล้วจะเห็น่าพจน์ด้านขวานั้นเป็นส่วนหนึ่งของการแจกแจงเบต้า(beta distribution) ของ $θ$ ที่มีค่าพารามิเตอร์ $α = y + 1$ และ $β = n − y + 1$ ดังนั้นจึงสามารถกำหนดค่าคงที่ที่ต้องการได้โดยไม่ต้องอินทิเกรตทำให้ได้การแจกแจงหลังการสังเกต(posterior distribution) ของ $θ$ เป็น \n",
    "\n",
    "$$h(θ \\mid x) =\\frac{Γ(n + 2) }{Γ(y + 1) Γ(n - y + 1)} θ^y (1 - θ)^{n - y}$$\n",
    "\n",
    "* สังเกตได้ว่าในกรณีนี้ เราสามารถเขียนการแจกแจงร่วมในรูปของค่าสถิติ $y =$ $\\sum_{i=1}^{n}$ $x_i$ นั่นคือเราไม่จำเป็นต้องทราบค่า $x_i$ แต่ละค่าสิ่งเดียวที่ต่องการทราบคือผลรวมหรือจำนวนสินค้าที่มีตำหนิเท่านั้น\n",
    "\n",
    "* หลักการนี้ช่วยให้เราวิเคราะห์ปัญหาที่สนใจได้สะดวกขึ้นมากเพราะค่าผลรวมนี้เป็นค่าสถิติที่รวบรวมเอาสารสนเทศ (information) ทั้งหมดจาก $x$ ที่จำเป็นในการวิเคราะห์ปัญหานี้ไว้อย่างครบถ้วนเราจะอภิปรายประเด็นนี้อย่างละเอียดในหัวข้อค่าสถิติที่เพียงพอ(sufﬁcient statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## การแปลงการแจกแจงได้ด้วยการปรับเป็นลำดับ (sequential updating)\n",
    "\n",
    "* ในกรณีที่มีตัวอย่างสุ่มมากกว่าหนึ่งตัวอย่างเราสามารถแปลงการแจกแจงได้ด้วยการปรับเป็นลำดับ(sequential updating) โดยเริ่มการแจกแจงหลังการสังเกต(posterior distribution) ซึ่งเป็นผลจากการสังเกต $X_1$\n",
    "\n",
    "<div align=\"right\">(3)</div>\n",
    "$$h(θ \\mid x_1) ∝ f(x_1 \\mid θ)h(θ)$$\n",
    "\n",
    "\n",
    "* หลังจากนั้นจึงคำนวณหาการแจกแจงหลังการสังเกต(posterior distribution) จาก $X_1, X_2$ โดยใช้ $h(θ \\mid x1)$ เป็นการแจกแจงก่อนการสังเกต(prior distribution)\n",
    "\n",
    "<div align=\"right\">(4)</div>\n",
    "$$h(θ \\mid x_1, x_2) ∝ f(x2 \\mid θ)h(θ \\mid x_1) ∝ f(x_1 \\mid θ)f(x_2 \\mid θ)h(θ)$$\n",
    "\n",
    "* ดังนั้น การดำเนินการในรูปแบบนี้ต่อไปจนครบทั้งหมด $n$ ครั้ง ก็จะได้การแจกแจงหลังการสังเกต(posterior distribution)\n",
    "\n",
    "<div align=\"right\">(5)</div>\n",
    "$$h(θ \\mid x) ∝ f(x_1 \\mid θ)···f(x_n \\mid θ)h(θ) = f(x \\mid θ)h(θ)$$\n",
    "    \n",
    "ตรงกับการแจกแจงหลังการสังเกต(posterior distribution) ที่แสดงในสมการ $(1)$ ซึ่งได้จากการปรับเพียงโดยใช้ข้อมูล $X_1,...,X_n$ เพียงครั้งเดียว \n",
    "    \n",
    "## ข้อสรุป : การแปลงการแจกแจงได้ด้วยการปรับเป็นลำดับ (sequential updating)\n",
    "    \n",
    "* อย่างไรก็ตามการปรับเป็นลำดับ(sequential updating) นี้มีความสำคัญอย่างมากในโลกของข้อมูลขนาดใหญ่ (bigdata) เพราะ **พัฒนาการทางเทคโนโลยีทำให้มีการเพิ่มข้อมูลตลอดเวลา**\n",
    "* ในขณะเดียวกันก็มีความต้องการพยากรณ์ที่ทันท่วงทีซึ่งในที่นี้สามารถทำได้โดยการปรับการแจกแจงทุกครั้งที่มีการรับข้อมูลเข้ามาใหม่ด้วยหลักการปรับเป็นลำดับ(sequential updating)ซึ่งป็น **พื้นฐานสำคัญอันหนึ่งของรูปแบบการเรียนรู้ของเครื่องจักร(machine learning)**\n",
    "* โดยทั่วไปการแจกแจงหลังการสังเกต(posterior distribution) จะมี **ความแตกต่าง** จากการแจกแจงก่อนการสังเกต(prior distribution) โดยสิ้นเชิง\n",
    "    \n",
    "    > ในตัวอย่างที่ผ่านมาเริ่มจากการแจกแจงเอกรูป (uniform distribution) แต่ได้การแจกแจงหลังการสังเกตที่เป็นการแจกแจงแบบเบต้า (beta distribution)\n",
    "    \n",
    "* บางครั้งมีการแจกแจงบางรูปแบบที่ถ้าเริ่มจากการแจกแจงก่อนการสังเกต(prior distribution) แล้วยังคงทำให้การแจกแจงหลังการสังเกต (posterior distribution) นั้นยังคงมีการแจกแจงเหมือนเดิมเราเรียกการแจกแจงที่มีคุณสมบัติแบบนี้วว่า **\"การแจกแจงก่อนการสังเกตคู (conjugate prior distribution)\"** \n",
    "    \n",
    "    > ตัวอย่างที่สำคัญอันหนึ่งของการแจกแจงก่อนการสังเกตคู่คือ การแจกแจงปกติ(normal distribution)\n",
    "    \n",
    "* นอกจากนี้เครื่องมือที่นิยมใช้ในการปรับการแจกแจงหรือปรับความเชื่อ (updating beliefs) ในทางเศรษฐศาสตร์และการเงินคือการกรองแบบคาลแมน (Kalman ﬁltering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ทฤษฎี : การแจกแจงก่อนการสังเกตคู่ (conjugate prior distribution) ของการแจกแจงปกติ (normal distribution)\n",
    "\n",
    "**<u>Theorem</u>**\n",
    "    \n",
    "สมมุติว่า $X_1,...,X_n$ คือตัวอย่างสุ่มที่สุ่มเลือกมาจากการแจกแจงปกติ (normal distribution) ที่มีค่าคาดหมายเท่ากับ $µ$ ซึ่งไม่ทราบค่าและค่าความแปรปรวนเท่ากับ $(σ_x)^2$ ซึ่งทราบค่าและสมมุติว่าการแจกแจงก่อนการสังเกต(prior distribution) ของ $µ$ เป็นการแจกแจงปกติ (normal distribution) ที่มีค่าคาดหมายเท่ากับ $µ_0$ และค่าความแปรปรวนเท่ากับ $(σ_0)^2$ แล้วการแจกแจง หลังการสังเกต (posterior distribution) ของ $µ$ หลังจากทราบค่าของ $X_1,...,X_n$ เป็นการแจกแจงปกติ (normal distribution) ที่มีค่าคาดหมายเท่ากับ $µ_1$ และค่าความแปรปรวนเท่ากับ $(σ_1)^2$ โดยที่\n",
    "\n",
    "<div align=\"right\">(6)</div>\n",
    "$$µ_1 = \\frac{(σ_x)^2}{(σ_x)^2 + n(σ_0)^2}µ_0 + \\frac{n(σ_x)^2}{(σ_x)^2 + n(σ_0)^2} (\\bar{x})_n$$\n",
    "\n",
    "<div align=\"right\">(7)</div>\n",
    "$$(σ_1)^2 = \\frac{(σ_x)^2}{(σ_x)^2 + n(σ_0)^2} (σ_0)^2$$\n",
    "    \n",
    "### การพิสูจน์: การแจกแจงก่อนการสังเกตคู่ (conjugate prior distribution) ของการแจกแจงปกติ (normal distribution) \n",
    "\n",
    "**<u>Proof.</u>**\n",
    "\n",
    "* พิจารณาฟังก์ชันความเป็นไปได้ (likelihood function) \n",
    "    \n",
    "$$f(x \\mid µ) ∝ exp [-\\frac{1}{2σ^2} \\sum_{i=1}^{n}(x_i - µ)^2]$$\n",
    "    \n",
    "* เนื่องจากสิ่งที่เราต้องการจริงๆ คือ รูปแบบของการแจกแจงหลังการสังเกต (posterior distribution) ที่เกี่ยวข้องกับ $µ$ ดังนั้น เราจึงสามารถที่จะละเลยพจน์ที่แยกออกไปและที่ไม่เกี่ยวข้องกับ $µ$ ได้โดยไม่ส่งผลเสียต้อสิ่งที่ต้องการพิสูจน์ โดยเริ่มจาก\n",
    "\n",
    "$$\\sum_{i=1}^{n} (x_i - µ)^2 = \\sum_{i=1}^{n} ((x_i - \\bar{x}_n) + (\\bar{x}_n - µ))^2 $$\n",
    "$$= \\sum_{i=1}^{n} (x_i - \\bar{x}_n)^2 + \\sum_{i=1}^{n} (\\bar{x}_n - µ)^2 + (\\bar{x}_n - µ) \\sum_{i=1}^{n} (x_i - \\bar{x}_n)$$\n",
    "\n",
    "<center>$=$ $\\sum_{i=1}^{n}$ $(µ - \\bar{x}_n)^2 +$ $\\sum_{i=1}^{n}$ $(x_i - \\bar{x}_n)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### การพิสูจน์: การแจกแจงก่อนการสังเกตคู่ (conjugate prior distribution) ของการแจกแจงปกติ (normal distribution) Con’t \n",
    "\n",
    "**<u>Proof.</u>**\n",
    "    \n",
    "* เนื่องจากพจน์ด้านขวาไม่ขึ้นอยู่กับ $µ$ ดังนั้น เราสามารถสรุปได้ว่าฟังก์ชันความเป็นไปได้ (likelihood function) \n",
    "\n",
    "$$f(x \\mid µ) ∝ exp [-\\frac{1}{2(σ_0)^2} n(µ - \\bar{x}_n)^2]$$\n",
    "    \n",
    "* ในขณะเดียวกันการแจกแจงก่อนการสังเกต (prior distibution) ของ $µ$ เขียนได้เป็น \n",
    "    \n",
    "$$h(µ) ∝ exp [ -\\frac{1}{2(σ_0)^2} (µ - µ_0)^2]$$\n",
    "    \n",
    "* ดังนั้น การแจกแจงหลังการสังเกต (posterior distribution) เท่ากับ\n",
    "    \n",
    "$$h(θ \\mid x) ∝ exp[ -\\frac{n}{2σ^2} (µ - \\bar{x}_n)^2] exp[ -\\frac{1}{2(σ_0)^2} (µ - µ_0)^2]$$\n",
    "    \n",
    "$$= exp -\\frac{1}{2} [ \\frac{n}{σ^2} (µ - \\bar{x}_n)^2 + \\frac{1}{(σ_0)^2} (µ - µ_0)^2]$$\n",
    "    \n",
    "* ขั้นตอนต่อไปคือการแยกพจน์ที่ไม่เกี่ยวกับ $µ$ ออกโดยการจัดรูป\n",
    "    \n",
    "$$\\frac{n}{σ_0^2} (µ - \\bar{x}_n)^2 + \\frac{1}{σ_0^2} (µ - µ_0)^2 = \\frac{n}{σ_0^2} (µ^2 - 2µ \\bar{x}_n + \\bar{x}_n^2) + \\frac{1}{σ_0^2} (µ^2 - 2µµ_0 + µ_0^2)$$\n",
    "    \n",
    "$$= \\frac{1}{σ^2 σ_0^2} [(σ^2 + nσ_0^2) µ^2 - 2(σ^2 µ_0 + nσ_0^2 \\bar{x}_n) µ] + \\frac{1}{σ^2 σ_0^2} [σ^2 µ_0^2 + nσ_0^2 \\bar{x}_n^2]$$\n",
    "    \n",
    "$$= \\frac{(σ^2 + nσ^2)}{σ^2 σ_0^2} [µ^2 - 2 \\frac{σ^2 µ_0 + nσ_0^2 \\bar{x}_n}{σ^2 + nσ_0^2} µ + (\\frac{σ^2 µ_0 + n σ_0^2 \\bar{x}_n)}{σ^2 + nσ_0^2})^2] + \\frac{1}{σ^2 σ_0^2} [σ^2 µ_0^2 + nσ_0^2 \\bar{x}_n^2 - (σ^2 + nσ_0^2) (\\frac{σ^2 µ_0 + nσ_0^2 \\bar{x}_n}{σ^2 nσ_0^2})^2]$$\n",
    "    \n",
    "$$= \\frac{1}{σ_1^2} (µ - µ_1)^2 + \\frac{n}{σ^2 + nσ^2} (\\bar{x}_n - µ_0)^2$$\n",
    "    \n",
    "โดยที่ $µ_1 =$ $\\frac{σ_x^2}{σ_x^2 + nσ_0^2}µ_0 +$ $\\frac{nσ_0^2}{σ_x^2 + nσ_0^2} \\bar{x}_n$ และ $σ_1^2 =$ $\\frac{(σ^2 + nσ_0^2)}{σ^2 + nσ_0^2}$  เนื่องจากพจน์ด้านขวาไม่เกี่ยวข้อง  $µ$\n",
    "\n",
    "* ดังนั้นเราสามารถสรุปได้ว่า\n",
    "    \n",
    "$$h(θ \\mid x) ∝ exp[ -\\frac{1}{σ_1^2} (µ - µ_1)^2]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ตัวอย่าง : การประมาณค่าแบบเบส์ (Bayes Estimator) ของความเสี่ยงเชิงระบบ(systematic risks) β\n",
    "    \n",
    "**<u>Example</u>**\n",
    "    \n",
    "พิจารณากองทุนหลักทรัพย์ AIT ในช่วงปี 2016 และสมมุติว่าความเสี่ยงเชิงระบบของหลักทรัพย์มีการแจกแจงปกติ (normal distribution) ที่มีความแปรปรวนคือ 14.56 $(σ_β^2 = 14.66)$ เราสามารถหาได้ว่า ความเสี่ยงเชิงระบบในช่วงปี 2016 คือ 0.91 $(β_{2016} = 0.91)$ ความแปรปรวนของความเสี่ยงเชิงระบบในช่วงปี 2016 คือ 0.04 $(σ_{2016}^2 = 0.04)$ และเมื่อใช้อัตราผลตอบแทนสุทธิ์รายสัปดาห์ทั้งสิ้น 52 สัปดาห (n = 52) และกำหนดให้ค่าเฉลี่ยของความเสี่ยงเชิงระบบในช่วงปี 2016 ของทุกหลักทรัพย์ที่อยูในตลาดคือ 0.77 $( β = 0.77)$ จงหา ความเสี่ยงเชิงระบบและความแปรปรวนของความเสี่ยงเชิงระบบในช่วงปี 2017 (วิธีการประมาณค่า $β$ แบบนี้เริ่มมาจากงาน วิจัยของ Vasicek(1973)) \n",
    "    \n",
    "* เราสามารถหาความเสี่ยงเชิงระบบและความแปรปรวนของความเสี่ยงเชิงระบบในช่วงปี 2017 ได้จากทฤษฎีก่อนหน้านี้\n",
    "\n",
    "    - ความเสี่ยงเชิงระบบในช่วงปี 2017\n",
    "    \n",
    "<div align=\"right\">(8)</div>\n",
    "$$β_{2017} = \\frac{σ_β^2}{σ_β^2 + nσ_{2016}^2} β_{2016} + \\frac{nσ_{2016}^2}{σ_β^2 + nσ_{2016}^2} \\bar{β}$$\n",
    "\n",
    "<div align=\"right\">(9)</div>\n",
    "$$= \\frac{14.66}{14.66 + 52 × 0.04} × 0.91 + \\frac{0.04}{14.66 + 52 × 0.04} × 0.77 \\approx 0.893$$\n",
    "\n",
    "\n",
    "    - ความแปรปรวนของความเสี่ยงเชิงระบบในช่วงปี 2017\n",
    "<div align=\"right\">(10)</div>\n",
    "$$σ_{2017}^2 = \\frac{σ_β^2}{σ_β^2 + nσ_{2016}^2} σ_{2016}^2$$\n",
    "\n",
    "<div align=\"right\">(11)</div>\n",
    "$$= \\frac{14.66}{14.66 + 52 × 0.04} × 0.04 \\approx 0.035$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## นิยาม : ฟังก์ชันสูญเสีย (loss function)\n",
    "\n",
    "* ตัวประมาณค่าแบบเบส์ (Bayes Estimator) ของ $θ$ คือตัวประมาณค่า (estimator) $\\hat{θ} (X_1,...,X_n)$ ซึ่งทำให้ค่าคาดหมายของฟังก์ชันสูญเสีย (loss function) ที่คำนวณโดยใช้ **การแจกแจงหลังการสังเกต (posterior distribution) มีค่าต่ำที่สุด”** \n",
    "    \n",
    "**<u>Definition</u>**\n",
    "ฟังก์ชันสูญเสีย (loss function) หมายถึงฟังก์ชันของสองกลุ่มตัวแปร $L(θ,a)$ ซึ่งตีความว่าเป็นการสูญเสียทางสถิติถ้าพารามิเตอร์มีค่าเท่ากับ $θ$ แต่ตัวประมาณค่ามีค่าเท่ากับ $a$\n",
    "\n",
    "* ในทางปฏิบัติเรามักจะใช้ **\"ค่าคาดหมายของการสูญเสีย (expected loss)\"**\n",
    "\n",
    "<div align=\"right\">(12)</div>\n",
    "$$E [L(θ,a) \\mid x] = \\int_Θ L(θ,a)h(θ \\mid x)dθ$$\n",
    "    \n",
    "เป็นฟังก์ชันเป้าหมาย (objective function) ที่ใช้ในการเลือกตัวประมาณค่าแบบเบส์ (Bayes Estimator)\n",
    "    \n",
    "## ตัวประมาณค่าแบบเบส์ (Bayes Estimator) \n",
    "    \n",
    "**<u>Definition</u>** กำหนดให้ $L(θ,a)$ แทนฟังก์ชันสูญเสีย (loss function) และ $\\hat{θ}(x)$ เป็นคำตอบของปัญหาการหาค่าต่ำสุด (minimization problem) ต่อไปนี้ \n",
    "\n",
    "<div align=\"right\">(13)</div>\n",
    "$$E[L(θ, \\hat{θ}(x))] = min_a E[L(θ,a) \\mid x ]$$\n",
    "    \n",
    "แล้วฟังก์ชัน $\\hat{θ}(x)$ คือตัวประมาณค่าแบบเบส์ (Bayes Estimator) ส่วนค่า $\\hat{θ}(x)$ คือค่าประมาณแบบเบส์ (Bayes estimate) ของ $θ$ เมื่อข้อมูลที่ใช้ในการประมาณค่า คือ $x$\n",
    "\n",
    "* ตัวประมาณค่าแบบเบส์ (Bayes Estimator) ขึ้นอยู่กับรูปแบบค่าคาดหมายของการสูญเสีย (expected loss) ซึ่งเป็นฟังก์ชันเป้าหมาย(objective function) \n",
    "* กล่าวอีกนัยหนึ่งได้ว่าการกำหนดรูปแบบฟังก์ชันสูญเสียที่ **แตกต่างกัน** ย่อมนำไปสู่ตัวประมาณค่าที่ **แตกต่างกัน** \n",
    "* ในขณะเดียวกัน ก็ **ไม่มีทฤษฎีที่บอกได้ว่าควรจะใช้ฟังก์ชันสูญเสียแบบใดดี** ดังนั้นจึงเป็นหน้าที่ของนักวิเคราะห์ที่จะต้องเลือกฟังก์ชันสูญเสียให้เหมาะสมซึ่งอาจจะต้องอาศัยประสบการณ์เป็นสำคัญ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## นิยาม: ฟังก์ชันสูญเสียกำลังสอง (square error loss function)\n",
    "\n",
    "**<u>Definition</u>**\n",
    "ฟังก์ชันสูญเสียกำลังสอง (square error loss function) นิยามได้เป็น\n",
    "\n",
    "<div align=\"right\">(14)</div>\n",
    "$$L( \\theta,a) = (  \\theta - a)^2$$\n",
    "\n",
    "ทฤษฎีบทต่อไปนี้ระบุว่า ค่าคาดหมายแบบมีเงื่อนไข (conditional expectation) คือตัวประมาณค่าแบบเบส์(Bayes Estimator) ในกรณีที่ฟังก์ชันสูญเสียเป็นแบบกำลังสอง(square error loss function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ตัวประมาณค่าแบบเบส์(Bayes Estimator) เมื่อใช้ฟังก์ชันสูญเสียกำลังสอง (square error loss function)\n",
    "\n",
    "**<u>Theorem</u>**\n",
    "\n",
    "สมมุติว่าฟังก์ชันสูญเสียที่ใช้สำหรับการประมาณค่าเป็นแบบฟังก์ชันสูญเสียกำลังสอง (square error loss function) ดังแสดงในสมการที่14 แล้ว ตัวประมาณค่าแบบเบส์\n",
    "(Bayes Estimator)\n",
    "\n",
    "<div align=\"right\">(15)</div>\n",
    "$$\\theta\\hat(X) = E[\\theta | X] =  \\int_{\\Theta}\\theta h(\\theta | X)d\\theta$$\n",
    "\n",
    "สังเกตว่า ค่าคาดหมายในที่นี้คำนวณจากการแจกแจงหลังการสังเกต (posterior distribution) ของ$\\theta$\n",
    "\n",
    "**<u>Proof.</u>**\n",
    "\n",
    "พิจารณาปัญหาการหาค่าคาดหมายของการสูญเสีย (expected loss) ที่ต่ำที่สุดดังต่อไปนี้\n",
    "\n",
    "$$min_{a}E[L( \\theta,a)| x] = min_{a}\\int_{\\Theta}\\theta h(\\theta | x)d\\theta$$\n",
    "\n",
    "เงื่อนไขอันดับที่หนึ่ง (first-order condition) สำหรับปัญหานี้คือ\n",
    "\n",
    "$$\\frac{\\partial E[L( \\theta,a)| x]}{\\partial a}\\vert_{a = \\theta\\hat(x)} = 0$$\n",
    "$$\\int_{\\Theta}\\frac{\\partial ( \\theta-a)^2}{\\partial a}h(\\theta | X)d\\theta = -2\\int_{\\Theta}( \\theta-\\theta\\hat(x))h(\\theta | X)d\\theta = 0  \\rightarrow \\theta\\hat(x) = \\int_{\\Theta}\\theta h(\\theta | X)d\\theta = E[\\theta | X]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ตัวอย่าง: ฟังก์ชันสูญเสียกำลังสอง (square error loss function)\n",
    "\n",
    "**<u>Example</u>**\n",
    "พิจารณาตัวอย่างสุ่ม $X1,....,Xn$ ซึ่งสุ่มเลือกมาจากการแจกแจงปกติ(normal distribution) ที่\n",
    "มีค่าคาดหมาย $\\mu$ และค่าความแปรปรวน $ \\sigma^2$ สมมุติว่าเราทราบค่าความแปรปรวน แต่ไม่ทราบค่าคาดหมาย ดังนั้น จึงต้องการประมาณค่าคาดหมาย $\\mu$ จากข้อมูลที่มีอยู่ด้วยการประมาณค่าแบบ\n",
    "เบส์(Bayes estimation) สมมุติอีกว่า การแจกแจงก่อนการสังเกต (prior distribution) ของ $\\mu$เป็นการแจกแจงแบบปกติ(normal distribution) ที่มีค่าคาดหมายเท่ากับ $\\mu_{0}$ และค่าความแปรปรวนเท่ากับ $\\sigma_{0}$\n",
    "\n",
    "* ทฤษฏีบทล่าสุดระบุว่าตัวประมาณค่าของเบส์ในกรณีที่ฟังก์ชันสูญเสียเป็นแบบกำลังสองคือค่าคาดหมายแบบมีเงื่อนไข (conditional expectation) นั่นคือ\n",
    "    \n",
    "$$\\theta\\hat(X) = E[\\theta | X] = \\frac{\\sigma_{x}^{2}}{\\sigma_{x}^{2}+n\\sigma_{0}^{2}}\\mu_{0}+\\frac{n\\sigma_{0}^{2}}{\\sigma_{x}^{2}+n\\sigma_{0}^{2}}\\bar X_{n} $$\n",
    "\n",
    "* ทฤษฏีบทต่อไปนี้แสดงถึงตัวประมาณค่าแบบเบส์ (Bayes Estimator) ในกรณีที่ฟังก์ชันสูญเสียเป็นแบบค่าสัมบูรณ์ของผลต่าง (absolute error loss function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## นิยาม: ฟังก์ชันสูญเสียแบบค่าสัมบูรณ์ของผลต่าง (absolute error loss function)\n",
    "\n",
    "**<u>Definition</u>**\n",
    "\n",
    "ฟังก์ชันสูญเสียแบบค่าสัมบูรณ์ของผลต่าง (absolute error loss function) นิยามได้เป็น\n",
    "\n",
    "<div align=\"right\">(16)</div>\n",
    "$$L( \\theta,a) = |\\theta-a|$$\n",
    "\n",
    "**<u>Theorem</u>**\n",
    "\n",
    "สมมุติว่าฟังก์ชันสูญเสียที่ใช้สำหรับการประมาณค่าเป็นแบบค่าสัมบูรณ์ของผลต่าง (absolute\n",
    "error loss function) ดังแสดงในสมการที่16 แล้ว ตัวประมาณค่าแบบเบส์(Bayes Estimator)\n",
    "มีค่าเท่ากับ **ค่ามัธยฐาน (median)** ของการแจกแจงหลังการสังเกต (posterior distribution)\n",
    "ของ $\\theta$\n",
    "\n",
    "* โดยทั่วไป ฟังก์ชันสูญเสียที่แตกต่างกันมักจะนำไปสู่ตัวประมาณค่าที่ต่างกันดังแสดงในทฤษฏีบทที่แล้ว\n",
    "\n",
    "* ค่าประมาณ (estimate) ที่ได้จากตัวประมาณที่แตกต่างกันมีค่าเท่ากัน ทั้งนี้ขึ้นอยู่กับรูปแบบการแจกแจงหลังการสังเกต"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ตัวอย่าง: ที่มีค่าคาดหมายและค่ามัธยฐานมีค่าเท่ากัน\n",
    "\n",
    "**<u>Example</u>**\n",
    "พิจารณาสถานการณ์ที่เหมือนกับตัวอย่างที่17 แต่คราวนี้กำหนดให้ฟังก์ชันสูญเสียที่ใช้สำหรับการ\n",
    "ประมาณค่าเป็นแบบค่าสัมบูรณ์ของผลต่าง (absolute error loss function) ดังนั้น จาก\n",
    "ทฤษฎีบทที่19 ตัวประมาณค่าแบบเบส์(Bayes Estimator) มีค่าเท่ากับค่ามัธยฐาน (median)\n",
    "ของการแจกแจงหลังการสังเกต (posterior distribution) ของ $\\mu$ ซึ่งในที่นี้จะมีค่าเท่ากับค่าคาดหมาย นั่นคือ\n",
    "\n",
    "$$\\theta\\hat(X) = E[\\theta | X] = \\frac{\\sigma_{x}^{2}}{\\sigma_{x}^{2}+n\\sigma_{0}^{2}}\\mu_{0}+\\frac{n\\sigma_{0}^{2}}{\\sigma_{x}^{2}+n\\sigma_{0}^{2}}\\bar X_{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## คุณสมบัติ: ความคงเส้นคงวาของตัวประมาณค่าแบบเบส์เมื่อตัวอย่างมีขนาดใหญ่\n",
    "\n",
    "* **ความคงเส้นคงวา (consistency)** เป็นคุณสมบัติการลู่เข้าของตัวประมาณค่าที่เกิดจากการเพิ่มขึ้นของ <u>ขนาดตัวอย่าง (sample size)</u> จนมีขนาดเข้าใกล้อนันต์(n $\\rightarrow$ ∞)โดยใช้หลักการลู่เข้าเชิงความน่าจะเป็น (convergence in probability) เป็นเครื่องมือในการวิเคราะห์\n",
    "\n",
    "* ถึงแม้ว่าในโลกความจริง เราจะไม่เคยมีข้อมูลขนาดอนันต์แต่หลักการความคงเส้นคงวา(consistency) ก็เป็นเครื่องมือทางสถิติที่มีประโยชน์และสะดวกในการใช้งาน โดยที่บางครั้งอาจจะเป็นเครื่องมือเดียวที่สามารถบอกถึงความแม่นยำของตัวประมาณค่า เพราะไม่สามารถพิสูจน์ในกรณีที่มีตัวอย่างจำกัดได้(finite sample)\n",
    "\n",
    "* คุณสมบัติของการลู่เข้าเชิงความน่าจะเป็น (convergence in probability) สามารถส่งผ่านฟังก์ชันที่ต่อเนื่องใดๆ ในขณะที่หลักการหาค่าคาดหมาย (expectation) สามารถส่งผ่านได้เพียงฟังก์ชันเชิงเส้นเท่านั้น"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## คุณสมบัติ: ความคงเส้นคงวาของตัวประมาณ\n",
    "\n",
    "**<u>Definition</u>**\n",
    "\n",
    "ตัวประมาณค่า $\\hat\\theta$ ของพารามิเตอร์ $\\theta$ มีความคงเส้นคงว่า (consistent) ถ้า\n",
    "\n",
    "\n",
    "$$\\hat\\theta \\rightarrow^p \\theta$$\n",
    "\n",
    "* คำถามคือ ตัวประมาณค่าแบบเบส์(Bayes estimator) มีความคงเส้นคงวา(consistent) หรือไม่?\n",
    "\n",
    "* คำตอบคือ ภายใต้เงื่อนไขที่ค่อนข้างมาตรฐาน ตัวประมาณค่าแบบเบส์(Bayes estimator)มีความคงเส้นคงวา (consistent)\n",
    "\n",
    "* แต่การพิสูจน์ความคงเส้นคงวาของตัวประมาณค่าแบบเบส์(Bayes estimator) อยู่เหนือขอบเขตของวิชานี้เพราะจำเป็นต้องใช้เทคนิคขั้นสูงของ ทฤษฎีการวัด (measuretheory)\n",
    "\n",
    "* แต่อย่างไรก็ตาม ยังสามารถแสดงให้เห็นถึงความคงเส้นคงวา (consistency) ของตัวประมาณค่าแบบเบส์(Bayes estimator) ได้อย่างไม่ยากเย็น โดยใช้ตัวอย่างต่อไปนี้"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ตัวอย่าง: ความคงเส้นคงวาของตัวประมาณ\n",
    "\n",
    "**<u>Example</u>**\n",
    "พิจารณาสถานการณ์ที่เหมือนกับตัวอย่างที่แล้วดังนั้น ตัวประมาณค่าแบบเบส์(Bayes\n",
    "estimator) เท่ากับ\n",
    "\n",
    "$$\\theta\\hat(X) = \\frac{\\sigma_{x}^{2}}{\\sigma_{x}^{2}+n\\sigma_{0}^{2}}\\mu_{0}+\\frac{n\\sigma_{0}^{2}}{\\sigma_{x}^{2}+n\\sigma_{0}^{2}}\\bar X_{n}$$\n",
    "\n",
    "* ขั้นตอนต่อไปคือ การตรวจสอบว่า $\\hat\\theta(X)$ ลู่เข้าเชิงความน่าจะเป็นสู่$\\mu$หรือไม่?\n",
    "\n",
    "$$plim_{n \\rightarrow \\infty}\\theta\\hat(X) = lim_{n \\rightarrow \\infty}[\\frac{\\sigma_{x}^{2}}{\\sigma_{x}^{2}+n\\sigma_{0}^{2}}]\\mu_{0}+lim_{n \\rightarrow \\infty}[\\frac{n\\sigma_{0}^{2}}{\\sigma_{x}^{2}+n\\sigma_{0}^{2}}]\\bar X_{n} = [0]\\mu_{0}+[1]plim_{n \\rightarrow \\infty}\\bar X_{n}$$\n",
    "\n",
    "* โดยที่สมการสุดท้ายเป็นผลมาจากกฎว่าด้วยตัวอย่างขนาดใหญ่(Law of Large Numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## สรุป: คุณสมบัติความคงเส้นคงวาของตัวประมาณค่าแบบเบส์เมื่อตัวอย่างมีขนาดใหญ่\n",
    "\n",
    "* บทเรียนอีกอย่างหนึ่งที่ได้จากตัวอย่างนี้คือ โดยทั่วไป การแจกแจงก่อนการสังเกต (priordistribution) ที่แตกต่างกัน มักนำไปสู่การแจกแจงหลังการสังเกต (posteriordistribution) ที่แตกต่างกัน ซึ่งส่งผลให้ได้ตัวประมาณค่าแบบเบส์(Bayes estimator) ที่แตกต่างกัน ด้วย\n",
    "\n",
    "* เมื่อ**ตัวอย่างมีขนาดใหญ่มากพอ**ผลของการแจกแจงก่อนการสังเกต (prior distribution)ดังกล่าว จะหมดไป ทำให้ได้ตัวประมาณค่าแบบเบส์(Bayes estimator) เหมือนกัน ไม่ว่าจะเริ่มด้วยการแจกแจงก่อนการสังเกต (prior distribution) แบบใด\n",
    "\n",
    "* หากพิจารณาจากมุมมองของการปรับเป็นลำดับ (sequential updating) อาจจะสรุปได้ว่าเมื่อเราปรับการแจกแจง (updating distribution) ไปเรื่อยๆ ก็จะได้ตัวประมาณค่าแบบเบส์(Bayes estimator) ที่เหมือนกัน ไม่ว่าจะเริ่มด้วยการแจกแจงก่อนการสังเกต (priordistribution) แบบใดก็ตาม"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ตัวอย่าง: คุณสมบัติความคงเส้นคงวาของตัวประมาณค่าแบบเบส์เมื่อมีการแจกแจงก่อนการสังเกต (prior distribution) 2 การแจกแจง\n",
    "\n",
    "**<u>Example</u>**\n",
    "ตัวอย่างต่อไปนี้แสดงการประมาณค่าแบบเบส์(Bayes estimation) จากการแจกแจงก่อนการ\n",
    "สังเกต (prior distribution) ที่แตกต่างกันสองอันคือ\n",
    "\n",
    "* อันแรกเป็นการแจกแจงปกติที่มีค่าคาดหมาย $\\mu_{0}= 10$ และค่าความแปรปรวน$\\sigma_{0}^2=10$ \n",
    "\n",
    "* ส่วนอันที่สองเป็นการแจกแจงปกติที่มีค่าคาดหมาย $\\mu_{0}= 100$ และค่าความแปรปรวน$\\sigma_{0}^2=100$ \n",
    "\n",
    "ในขณะที่กลุ่มตัวอย่างที่ใช้ในตัวอย่างนี้สุ่มเลือกมาจากการแจกแจงปกติที่มีค่าคาดหมาย\n",
    "$\\mu = 50$ และค่าความแปรปรวน $\\sigma^2 = 50$ (ด้วยการจำลอง (simulation) ในคอมพิวเตอร์)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Example</u>**\n",
    "คุณสมบัติความคงเส้นคงวาของตัวประมาณค่าแบบเบส์เมื่อมีการแจกแจงก่อนการสังเกต (prior distribution) 2 การแจกแจง\n",
    "\n",
    "* รูปแสดงค่าประมาณแบบเบส์(Bayes estimate) สำหรับการแจกแจงก่อนการสังเกต (priordistribution) ทั้งสองการแจกแจง\n",
    "    \n",
    "<img src=\"images/12.1.png\" width=500>\n",
    "    \n",
    "* บทเรียนที่สำคัญจากตัวอย่างนี้คือ\n",
    "\n",
    "    - ในช่วงแรกที่ขนาดของตัวอย่างยัง**ไม่มากนัก**ค่าประมาณแบบเบส์(Bayes estimate) ที่ได้จากการแจกแจงก่อนการสังเกต (prior distribution) ทั้งสองอัน มี**ความแตกต่างกันอย่างชัดเจน**\n",
    "    - เมื่อตัวอย่างมี**จำนวนมากพอ ความแตกต่างดังกล่าวแทบจะไม่เหลืออยู่เลย**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
